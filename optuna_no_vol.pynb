{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04f5e3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  4 of 4 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price            Close                                              High  \\\n",
      "Ticker            AAPL        MSFT           NDX         SPY        AAPL   \n",
      "Date                                                                       \n",
      "2021-06-01  121.253769  237.943253  13654.589844  393.035126  122.297714   \n",
      "2021-06-02  122.014786  237.847031  13675.790039  393.653229  122.190403   \n",
      "2021-06-03  120.531815  236.317841  13529.679688  392.192139  121.809914   \n",
      "2021-06-04  122.824577  241.203644  13770.769531  395.779114  123.088007   \n",
      "2021-06-07  122.834328  244.108170  13802.889648  395.395142  123.244099   \n",
      "...                ...         ...           ...         ...         ...   \n",
      "2024-12-24  256.797211  435.119690  21797.650391  594.320740  256.807136   \n",
      "2024-12-26  257.612701  433.911438  21768.310547  594.360352  258.686851   \n",
      "2024-12-27  254.201370  426.404083  21473.009766  588.103760  257.294489   \n",
      "2024-12-30  250.829788  420.758698  21197.089844  581.392578  252.122728   \n",
      "2024-12-31  249.059464  417.460602  21012.169922  579.277405  251.903926   \n",
      "\n",
      "Price                                                    Low              \\\n",
      "Ticker            MSFT           NDX         SPY        AAPL        MSFT   \n",
      "Date                                                                       \n",
      "2021-06-01  241.684559  13654.589844  395.891542  120.922052  237.520084   \n",
      "2021-06-02  239.741729  13675.790039  394.496132  121.029385  236.442832   \n",
      "2021-06-03  236.923749  13529.679688  393.334711  120.131794  233.711423   \n",
      "2021-06-04  242.030771  13770.769531  396.078811  120.834250  238.049022   \n",
      "2021-06-07  244.377465  13802.889648  395.947693  121.790383  240.261069   \n",
      "...                ...           ...         ...         ...         ...   \n",
      "2024-12-24  435.387122  21797.650391  594.360314  253.903002  430.028965   \n",
      "2024-12-26  436.714334  21768.310547  595.487074  256.230269  432.445641   \n",
      "2024-12-27  431.049140  21473.009766  590.841628  251.685117  422.264149   \n",
      "2024-12-30  423.452632  21197.089844  584.871741  249.387669  417.856784   \n",
      "2024-12-31  422.640492  21012.169922  583.784475  248.074837  416.628655   \n",
      "\n",
      "Price                                       Open                            \\\n",
      "Ticker               NDX         SPY        AAPL        MSFT           NDX   \n",
      "Date                                                                         \n",
      "2021-06-01  13654.589844  392.594954  122.034292  241.626854  13654.589844   \n",
      "2021-06-02  13675.790039  392.679254  121.253780  238.645306  13675.790039   \n",
      "2021-06-03  13529.679688  389.860179  121.644055  235.846565  13529.679688   \n",
      "2021-06-04  13770.769531  392.257738  121.048895  238.289466  13770.769531   \n",
      "2021-06-07  13802.889648  394.458608  123.097750  240.424569  13802.889648   \n",
      "...                  ...         ...         ...         ...           ...   \n",
      "2024-12-24  21797.650391  588.558391  254.101927  430.484548  21797.650391   \n",
      "2024-12-26  21768.310547  591.138180  256.787224  434.872143  21768.310547   \n",
      "2024-12-27  21473.009766  583.903089  256.429191  430.435086  21473.009766   \n",
      "2024-12-30  21197.089844  577.626803  250.859624  421.976921  21197.089844   \n",
      "2024-12-31  21012.169922  577.636639  251.068493  422.016524  21012.169922   \n",
      "\n",
      "Price                     Volume                           \n",
      "Ticker             SPY      AAPL      MSFT  NDX       SPY  \n",
      "Date                                                       \n",
      "2021-06-01  395.751068  67637100  23213300  0.0  54216600  \n",
      "2021-06-02  393.690698  59278900  19406700  0.0  49097100  \n",
      "2021-06-03  391.330544  76229200  25307700  0.0  58138800  \n",
      "2021-06-04  394.046521  75169300  25281100  0.0  55938800  \n",
      "2021-06-07  395.769749  71057600  23079200  0.0  51555000  \n",
      "...                ...       ...       ...  ...       ...  \n",
      "2024-12-24  589.141570  23234700   7164500  0.0  33160100  \n",
      "2024-12-26  592.541682  27237100   8194200  0.0  41219100  \n",
      "2024-12-27  590.604363  42355300  18117700  0.0  64969300  \n",
      "2024-12-30  581.066452  35557500  13158700  0.0  56578800  \n",
      "2024-12-31  583.062907  39480700  13246500  0.0  57052700  \n",
      "\n",
      "[903 rows x 20 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/aidev/patchtst_timeseries/.venv/lib/python3.13/site-packages/pandas/core/internals/blocks.py:347: RuntimeWarning: divide by zero encountered in log\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import PatchTST\n",
    "import logging\n",
    "import os\n",
    "os.environ[\"HTTP_PROXY\"]  = \"http://proxy.isoad.isogmbh.de:81\"\n",
    "os.environ[\"HTTPS_PROXY\"] = \"http://proxy.isoad.isogmbh.de:81\"\n",
    "\n",
    "\n",
    "tickers = ['AAPL', 'SPY', 'MSFT', 'NDX' ]\n",
    "period = {'start':'2021-06-01', 'end':'2025-01-01'}\n",
    "df_raw_multi = yf.download(tickers, start=period['start'], end=period['end'])\n",
    "print(df_raw_multi)\n",
    "#cleanup\n",
    "\n",
    "# 2. BASIS-BERECHNUNG (Log-Returns & Volumen)\n",
    "df_close_log = np.log(df_raw_multi['Close'] / df_raw_multi['Close'].shift(1))\n",
    "df_vol_log = np.log(df_raw_multi['Volume']).diff()\n",
    "\n",
    "train_dates = df_close_log\n",
    "\n",
    "df_list = []\n",
    "for ticker in tickers:\n",
    "    temp_df = pd.DataFrame({\n",
    "        'ds': df_close_log.index,\n",
    "        'unique_id': ticker,\n",
    "        'y': df_close_log[ticker],\n",
    "        'volume': df_vol_log[ticker]\n",
    "    }).dropna()\n",
    "    df_list.append(temp_df)\n",
    "\n",
    "df_train_multi = pd.concat(df_list).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b8c1692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-20 11:20:29,184]\u001b[0m A new study created in memory with name: no-name-07fe8276-1b34-4171-9dd5-aee196519eb3\u001b[0m\n",
      "Seed set to 1\n",
      "\u001b[33m[W 2026-02-20 11:20:29,191]\u001b[0m Trial 0 failed with parameters: {'input_size': 110, 'patch_len': 8, 'stride': 2, 'encoder_layers': 2, 'n_heads': 2, 'hidden_size': 128, 'linear_hidden_size': 128, 'dropout': 0.18311584881834395, 'learning_rate': 0.00012128277162091374} because of the following error: Exception('PatchTST does not support historical exogenous variables.').\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"/home/aidev/patchtst_timeseries/.venv/lib/python3.13/site-packages/optuna/study/_optimize.py\"\u001b[0m, line \u001b[35m206\u001b[0m, in \u001b[35m_run_trial\u001b[0m\n",
      "    value_or_values = func(trial)\n",
      "  File \u001b[35m\"/tmp/ipykernel_2896847/1214992454.py\"\u001b[0m, line \u001b[35m23\u001b[0m, in \u001b[35mobjective\u001b[0m\n",
      "    model = PatchTST(\n",
      "        h=7,\n",
      "    ...<15 lines>...\n",
      "        enable_progress_bar=False,\n",
      "    )\n",
      "  File \u001b[35m\"/home/aidev/patchtst_timeseries/.venv/lib/python3.13/site-packages/neuralforecast/models/patchtst.py\"\u001b[0m, line \u001b[35m928\u001b[0m, in \u001b[35m__init__\u001b[0m\n",
      "    \u001b[31msuper(PatchTST, self).__init__\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "        \u001b[1;31mh=h,\u001b[0m\n",
      "        \u001b[1;31m^^^^\u001b[0m\n",
      "    ...<28 lines>...\n",
      "        \u001b[1;31m**trainer_kwargs\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    \u001b[1;31m)\u001b[0m\n",
      "    \u001b[1;31m^\u001b[0m\n",
      "  File \u001b[35m\"/home/aidev/patchtst_timeseries/.venv/lib/python3.13/site-packages/neuralforecast/common/_base_model.py\"\u001b[0m, line \u001b[35m240\u001b[0m, in \u001b[35m__init__\u001b[0m\n",
      "    raise Exception(\n",
      "        f\"{type(self).__name__} does not support historical exogenous variables.\"\n",
      "    )\n",
      "\u001b[1;35mException\u001b[0m: \u001b[35mPatchTST does not support historical exogenous variables.\u001b[0m\n",
      "\u001b[33m[W 2026-02-20 11:20:29,194]\u001b[0m Trial 0 failed with value None.\u001b[0m\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "PatchTST does not support historical exogenous variables.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mException\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 75\u001b[39m\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.mean(fold_hit_rates)\n\u001b[32m     68\u001b[39m study = optuna.create_study(\n\u001b[32m     69\u001b[39m     direction=\u001b[33m'\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m'\u001b[39m,  \u001b[38;5;66;03m# higher hit rate = better\u001b[39;00m\n\u001b[32m     70\u001b[39m     pruner=optuna.pruners.MedianPruner(\n\u001b[32m   (...)\u001b[39m\u001b[32m     73\u001b[39m     )\n\u001b[32m     74\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3600\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTickers\u001b[39m\u001b[33m\"\u001b[39m, tickers)\n\u001b[32m     78\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPeriod\u001b[39m\u001b[33m\"\u001b[39m, period)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/patchtst_timeseries/.venv/lib/python3.13/site-packages/optuna/study/study.py:490\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    398\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/patchtst_timeseries/.venv/lib/python3.13/site-packages/optuna/study/_optimize.py:68\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     81\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/patchtst_timeseries/.venv/lib/python3.13/site-packages/optuna/study/_optimize.py:165\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    162\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m     frozen_trial_id = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    167\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    168\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    170\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    171\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/patchtst_timeseries/.venv/lib/python3.13/site-packages/optuna/study/_optimize.py:263\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    256\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    258\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    259\u001b[39m     updated_state == TrialState.FAIL\n\u001b[32m    260\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    261\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    262\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m263\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial._trial_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/patchtst_timeseries/.venv/lib/python3.13/site-packages/optuna/study/_optimize.py:206\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    205\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    207\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    208\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    209\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mobjective\u001b[39m(trial):\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     model = \u001b[43mPatchTST\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m        \u001b[49m\u001b[43mh\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m.\u001b[49m\u001b[43msuggest_int\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43minput_size\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m120\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpatch_len\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m.\u001b[49m\u001b[43msuggest_categorical\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpatch_len\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m.\u001b[49m\u001b[43msuggest_categorical\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mstride\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_layers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m.\u001b[49m\u001b[43msuggest_int\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mencoder_layers\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_heads\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m.\u001b[49m\u001b[43msuggest_categorical\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mn_heads\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m.\u001b[49m\u001b[43msuggest_categorical\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhidden_size\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlinear_hidden_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m.\u001b[49m\u001b[43msuggest_categorical\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlinear_hidden_size\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m256\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m.\u001b[49m\u001b[43msuggest_float\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdropout\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m.\u001b[49m\u001b[43msuggest_float\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlearning_rate\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhist_exog_list\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mvolume\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m        \u001b[49m\u001b[43mval_check_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m        \u001b[49m\u001b[43mearly_stop_patience_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccelerator\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mgpu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevices\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m        \u001b[49m\u001b[43menable_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m     nf = NeuralForecast(models=[model], freq=\u001b[33m'\u001b[39m\u001b[33mD\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     45\u001b[39m     all_dates = np.sort(df_train_multi[\u001b[33m'\u001b[39m\u001b[33mds\u001b[39m\u001b[33m'\u001b[39m].unique())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/patchtst_timeseries/.venv/lib/python3.13/site-packages/neuralforecast/models/patchtst.py:928\u001b[39m, in \u001b[36mPatchTST.__init__\u001b[39m\u001b[34m(self, h, input_size, stat_exog_list, hist_exog_list, futr_exog_list, exclude_insample_y, encoder_layers, n_heads, hidden_size, linear_hidden_size, dropout, fc_dropout, head_dropout, attn_dropout, patch_len, stride, revin, revin_affine, revin_subtract_last, activation, res_attention, batch_normalization, learn_pos_embed, loss, valid_loss, max_steps, learning_rate, num_lr_decays, early_stop_patience_steps, val_check_steps, batch_size, valid_batch_size, windows_batch_size, inference_windows_batch_size, start_padding_enabled, training_data_availability_threshold, step_size, scaler_type, random_seed, drop_last_loader, alias, optimizer, optimizer_kwargs, lr_scheduler, lr_scheduler_kwargs, dataloader_kwargs, **trainer_kwargs)\u001b[39m\n\u001b[32m    878\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    879\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    880\u001b[39m     h,\n\u001b[32m   (...)\u001b[39m\u001b[32m    926\u001b[39m     **trainer_kwargs\n\u001b[32m    927\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m928\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mPatchTST\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m        \u001b[49m\u001b[43mh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstat_exog_list\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstat_exog_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhist_exog_list\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhist_exog_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfutr_exog_list\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfutr_exog_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexclude_insample_y\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude_insample_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m        \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalid_loss\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalid_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_lr_decays\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_lr_decays\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m        \u001b[49m\u001b[43mearly_stop_patience_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mearly_stop_patience_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m        \u001b[49m\u001b[43mval_check_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_check_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalid_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalid_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwindows_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwindows_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43minference_windows_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43minference_windows_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstart_padding_enabled\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart_padding_enabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtraining_data_availability_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining_data_availability_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstep_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstep_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscaler_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscaler_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdrop_last_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdrop_last_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m        \u001b[49m\u001b[43malias\u001b[49m\u001b[43m=\u001b[49m\u001b[43malias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptimizer_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr_scheduler_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr_scheduler_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdataloader_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataloader_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtrainer_kwargs\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    961\u001b[39m     \u001b[38;5;66;03m# Enforce correct patch_len, regardless of user input\u001b[39;00m\n\u001b[32m    962\u001b[39m     patch_len = \u001b[38;5;28mmin\u001b[39m(input_size + stride, patch_len)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/patchtst_timeseries/.venv/lib/python3.13/site-packages/neuralforecast/common/_base_model.py:240\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, h, input_size, loss, valid_loss, learning_rate, max_steps, val_check_steps, batch_size, valid_batch_size, windows_batch_size, inference_windows_batch_size, start_padding_enabled, training_data_availability_threshold, n_series, n_samples, h_train, inference_input_size, step_size, num_lr_decays, early_stop_patience_steps, scaler_type, futr_exog_list, hist_exog_list, stat_exog_list, exclude_insample_y, drop_last_loader, random_seed, alias, optimizer, optimizer_kwargs, lr_scheduler, lr_scheduler_kwargs, dataloader_kwargs, **trainer_kwargs)\u001b[39m\n\u001b[32m    236\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[32m    237\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not support future exogenous variables.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    238\u001b[39m     )\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.EXOGENOUS_HIST \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.hist_exog_size > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[32m    241\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not support historical exogenous variables.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    242\u001b[39m     )\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.EXOGENOUS_STAT \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stat_exog_size > \u001b[32m0\u001b[39m:\n\u001b[32m    244\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[32m    245\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not support static exogenous variables.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    246\u001b[39m     )\n",
      "\u001b[31mException\u001b[39m: PatchTST does not support historical exogenous variables."
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import PatchTST\n",
    "from neuralforecast.losses.pytorch import MAE\n",
    "from pathlib import Path\n",
    "N_FOLDS = 4\n",
    "FOLD_STEP = 20  # trading days between fold cutoffs\n",
    "\n",
    "study_id = \"_\".join(tickers) + '.' + period['start'] + '.' + period['end']\n",
    "report_dir = \"optuna_report\"\n",
    "\n",
    "rdir = Path(report_dir, study_id)\n",
    "rdir.mkdir(parents=True, exist_ok=True)\n",
    "#dump data\n",
    "df_train_multi.to_csv(rdir / \"traindata.csv\",            # file name (or pathlib.Path)\n",
    "          index=False,              # omit the row‑index column (optional)\n",
    "          sep=\",\",                  # column separator (default ',')\n",
    "          header=True,              # write column names (default True)\n",
    ")\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    model = PatchTST(\n",
    "        h=7,\n",
    "        input_size=trial.suggest_int('input_size', 30, 120, step=10),\n",
    "        patch_len=trial.suggest_categorical('patch_len', [4, 8, 16]),\n",
    "        stride=trial.suggest_categorical('stride', [2, 4, 8]),\n",
    "        encoder_layers=trial.suggest_int('encoder_layers', 1, 3),\n",
    "        n_heads=trial.suggest_categorical('n_heads', [2, 4, 8]),\n",
    "        hidden_size=trial.suggest_categorical('hidden_size', [32, 64, 128]),\n",
    "        linear_hidden_size=trial.suggest_categorical('linear_hidden_size', [64, 128, 256]),\n",
    "        dropout=trial.suggest_float('dropout', 0.0, 0.3),\n",
    "        learning_rate=trial.suggest_float('learning_rate', 1e-4, 1e-3, log=True),\n",
    "        hist_exog_list=['volume'],\n",
    "        max_steps=500,\n",
    "        val_check_steps=500,\n",
    "        early_stop_patience_steps=-1,\n",
    "        accelerator='gpu',\n",
    "        devices=1,\n",
    "        enable_progress_bar=False,\n",
    "    )\n",
    "\n",
    "    nf = NeuralForecast(models=[model], freq='D')\n",
    "\n",
    "    all_dates = np.sort(df_train_multi['ds'].unique())\n",
    "    n_total = len(all_dates)\n",
    "\n",
    "    fold_hit_rates = []\n",
    "    for fold in range(N_FOLDS):\n",
    "        cutoff = all_dates[n_total - FOLD_STEP * (N_FOLDS - fold)]\n",
    "        df_fold = df_train_multi[df_train_multi['ds'] <= cutoff]\n",
    "\n",
    "        cv = nf.cross_validation(df=df_fold, n_windows=3, step_size=1, refit=False)\n",
    "\n",
    "        \n",
    "        actual_dir = np.sign(cv['y']) # Directional accuracy — what actually drives P&L\n",
    "        pred_dir   = np.sign(cv['PatchTST'])\n",
    "        hit_rate   = (actual_dir == pred_dir).mean()\n",
    "        fold_hit_rates.append(hit_rate)\n",
    "\n",
    "        trial.report(hit_rate, step=fold)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return np.mean(fold_hit_rates)\n",
    "\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction='maximize',  # higher hit rate = better\n",
    "    pruner=optuna.pruners.MedianPruner(\n",
    "        n_startup_trials=5,\n",
    "        n_warmup_steps=1,\n",
    "    )\n",
    ")\n",
    "study.optimize(objective, n_trials=50, timeout=3600)\n",
    "\n",
    "print(\"Tickers\", tickers)\n",
    "print(\"Period\", period)\n",
    "print(\"Best params:    \", study.best_params)\n",
    "print(\"Best params:    \", study.best_params)\n",
    "print(\"Best hit rate:  \", study.best_value)\n",
    "\n",
    "df_trials = study.trials_dataframe()\n",
    "print(df_trials.sort_values('value', ascending=False).head(10))\n",
    "\n",
    "\n",
    "#report file\n",
    "with open(rdir / \"optuna_summary.txt\", \"w\") as reportfile:\n",
    "    \n",
    "    \n",
    "    print(\"Best params:   \", study.best_params, file=reportfile)\n",
    "    print(\"Best hit rate: \", study.best_value, file=reportfile)\n",
    "\n",
    "\n",
    "df_trials.sort_values(\"value\", ascending=False).to_csv(rdir / \"optuna_trials.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "patchtst_timeseries (3.13.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
