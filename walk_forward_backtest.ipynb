{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0957422d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  2 of 2 completed\n",
      "Seed set to 1\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "ðŸ’¡ Tip: For seamless cloud logging and experiment tracking, try installing [litlogger](https://pypi.org/project/litlogger/) to enable LitLogger, which logs metrics and artifacts automatically to the Lightning Experiments platform.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/aidev/patchtst_timeseries/.venv/lib/python3.13/site-packages/neuralforecast/common/_base_model.py:632: UserWarning: ignoring optimizer_kwargs as the optimizer is not specified\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name         | Type              | Params | Mode  | FLOPs\n",
      "-------------------------------------------------------------------\n",
      "0 | loss         | MAE               | 0      | train | 0    \n",
      "1 | padder_train | ConstantPad1d     | 0      | train | 0    \n",
      "2 | scaler       | TemporalNorm      | 0      | train | 0    \n",
      "3 | model        | PatchTST_backbone | 408 K  | train | 0    \n",
      "-------------------------------------------------------------------\n",
      "408 K     Trainable params\n",
      "3         Non-trainable params\n",
      "408 K     Total params\n",
      "1.632     Total estimated model params size (MB)\n",
      "90        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "0         Total Flops\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aidev/patchtst_timeseries/.venv/lib/python3.13/site-packages/pytorch_lightning/utilities/_pytree.py:21: `isinstance(treespec, LeafSpec)` is deprecated, use `isinstance(treespec, TreeSpec) and treespec.is_leaf()` instead.\n",
      "/home/aidev/patchtst_timeseries/.venv/lib/python3.13/site-packages/pytorch_lightning/utilities/_pytree.py:21: `isinstance(treespec, LeafSpec)` is deprecated, use `isinstance(treespec, TreeSpec) and treespec.is_leaf()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.67it/s, v_num=6, train_loss_step=0.100, train_loss_epoch=0.100, valid_loss=0.116]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=300` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.97it/s, v_num=6, train_loss_step=0.100, train_loss_epoch=0.100, valid_loss=0.116]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "ðŸ’¡ Tip: For seamless cloud logging and experiment tracking, try installing [litlogger](https://pypi.org/project/litlogger/) to enable LitLogger, which logs metrics and artifacts automatically to the Lightning Experiments platform.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/aidev/patchtst_timeseries/.venv/lib/python3.13/site-packages/pytorch_lightning/utilities/_pytree.py:21: `isinstance(treespec, LeafSpec)` is deprecated, use `isinstance(treespec, TreeSpec) and treespec.is_leaf()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 66.43it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_raw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 84\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i + \u001b[32m1\u001b[39m < \u001b[38;5;28mlen\u001b[39m(test_dates):\n\u001b[32m     83\u001b[39m     next_day = test_dates[i+\u001b[32m1\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     actual_ret = \u001b[43mdf_raw\u001b[49m.loc[next_day, \u001b[33m'\u001b[39m\u001b[33my_log\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     86\u001b[39m     \u001b[38;5;66;03m# Kosten nur bei Signalwechsel\u001b[39;00m\n\u001b[32m     87\u001b[39m     cost = FEE \u001b[38;5;28;01mif\u001b[39;00m signal != current_pos \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'df_raw' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import PatchTST\n",
    "import logging\n",
    "import os\n",
    "# Set both HTTP and HTTPS proxies\n",
    "os.environ[\"HTTP_PROXY\"]  = \"http://proxy.isoad.isogmbh.de:81\"\n",
    "os.environ[\"HTTPS_PROXY\"] = \"http://proxy.isoad.isogmbh.de:81\"\n",
    "\n",
    "# 1. EINMALIGER DOWNLOAD (AuÃŸerhalb der Schleife)\n",
    "tickers = ['AAPL', 'SPY']\n",
    "df_raw_multi = yf.download(tickers, start='2021-06-01', end='2025-01-01')\n",
    "\n",
    "# 2. BASIS-BERECHNUNG (Log-Returns & Volumen)\n",
    "# Wir berechnen hier nur die Roh-Features, die keine Roll-Fenster nutzen\n",
    "df_close_log = np.log(df_raw_multi['Close'] / df_raw_multi['Close'].shift(1))\n",
    "df_vol_log = np.log(df_raw_multi['Volume']).diff()\n",
    "\n",
    "# 3. DIE SCHLEIFE\n",
    "test_dates = df_close_log['2024-01-01':].index\n",
    "portfolio_value = 10000.0\n",
    "current_pos = 0\n",
    "THRESHOLD = 0.000553\n",
    "FEE = 0.0005\n",
    "\n",
    "for i, today in enumerate(test_dates):\n",
    "    # --- DATEN-FENSTER FÃœR HEUTE ERSTELLEN ---\n",
    "    df_list = []\n",
    "    for t in tickers:\n",
    "        # Nur Daten bis 'today'\n",
    "        mask = df_close_log.index <= today\n",
    "        \n",
    "        # Preis-KanÃ¤le\n",
    "        df_list.append(pd.DataFrame({\n",
    "            'ds': df_close_log.index[mask],\n",
    "            'unique_id': f'{t}_price',\n",
    "            'y': df_close_log[t][mask]\n",
    "        }))\n",
    "        # Volumen-KanÃ¤le\n",
    "        df_list.append(pd.DataFrame({\n",
    "            'ds': df_vol_log.index[mask],\n",
    "            'unique_id': f'{t}_vol',\n",
    "            'y': df_vol_log[t][mask]\n",
    "        }))\n",
    "\n",
    "    df_step = pd.concat(df_list).dropna()\n",
    "    \n",
    "    # Momentum-Target berechnen (NUR auf den Daten bis heute!)\n",
    "    df_step['y_rolling'] = df_step.groupby('unique_id')['y'].transform(lambda x: x - x.rolling(5).mean())\n",
    "    df_step = df_step.dropna().rename(columns={'y': 'y_raw', 'y_rolling': 'y'})\n",
    "    \n",
    "    # --- MODELL-TRAINING (Dein Stable Setup) ---\n",
    "    model = PatchTST(\n",
    "        h=7,\n",
    "        input_size=10,\n",
    "        patch_len=2,\n",
    "        stride=1,\n",
    "        max_steps=300,\n",
    "        learning_rate=5e-5,\n",
    "        early_stop_patience_steps=3,\n",
    "        val_check_steps=50,\n",
    "        optimizer_kwargs={'weight_decay': 0.01},\n",
    "        accelerator='gpu',\n",
    "        devices=1\n",
    "    )\n",
    "\n",
    "    nf = NeuralForecast(models=[model], freq='D')\n",
    "    nf.fit(df=df_step, val_size=20)\n",
    "    # Prediction fÃ¼r den nÃ¤chsten Tag\n",
    "    forecast = nf.predict(df=df_step)\n",
    "    # Wir nehmen den ersten Tag des Horizonts (t+1)\n",
    "    pred_momentum = forecast.query(\"unique_id == 'AAPL_price'\").iloc[0]['PatchTST']\n",
    "    \n",
    "    # Signal Logik\n",
    "    signal = 0\n",
    "    if pred_momentum > THRESHOLD: signal = 1\n",
    "    elif pred_momentum < -THRESHOLD: signal = -1\n",
    "    \n",
    "    # Abrechnung (am nÃ¤chsten Handelstag)\n",
    "    if i + 1 < len(test_dates):\n",
    "        next_day = test_dates[i+1]\n",
    "        actual_ret = df_raw.loc[next_day, 'y_raw']\n",
    "        \n",
    "        # Kosten nur bei Signalwechsel\n",
    "        cost = FEE if signal != current_pos else 0\n",
    "        daily_profit = (signal * actual_ret) - cost\n",
    "        portfolio_value *= np.exp(daily_profit)\n",
    "        current_pos = signal\n",
    "        \n",
    "        # Output & Log\n",
    "        print(f\"{today.date()} | Pred: {pred_momentum:.5f} | Signal: {signal} | Port: {portfolio_value:.2f}â‚¬\")\n",
    "        with open(log_file, 'a') as f:\n",
    "            f.write(f\"{today.date()},{pred_momentum},{signal},{actual_ret},{portfolio_value}\\n\")\n",
    "\n",
    "    #return log_file\n",
    "\n",
    "# Start den Prozess\n",
    "#run_stable_walk_forward()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "patchtst_timeseries",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
